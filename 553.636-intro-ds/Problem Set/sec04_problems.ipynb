{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 04 \n",
    "### Introduction to Data Science EN.553.436/EN.553.636 - Fall 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge Regression and LASSO Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1\n",
    "Below we load the [Boston house prices dataset](https://scikit-learn.org/stable/datasets/toy_dataset.html#boston-dataset). We store the labels of predictors for you and split the dataset into a training and test set using 1/3 as the test size and a random state of 553."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(339, 13)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "boston_bunch = load_boston()\n",
    "X = boston_bunch.data\n",
    "y = boston_bunch.target\n",
    "labels = boston_bunch.feature_names\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=553)\n",
    "\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1\n",
    "In the homework1, we built three different linear models by OLS to predict house price (MEDV) and calculated their $R^{2}$'s. The models of using all the 13 predictor variables and using the polynomial combinations of the 13 predictor variables both have high $R^{2}$'s. But is it optimal to use all the predictor variables? Compute the variance, bias and the Mean Squared Error (MSE) of three models we built in the homework1. What can be observed?\n",
    "\n",
    "(Import the function bias_variance_decomp() from mlxtend.evaluate to calculate the variance, bias and the MSE.\n",
    "You may see more details here: http://rasbt.github.io/mlxtend/user_guide/evaluate/bias_variance_decomp/#api. \n",
    "And the source code of the function is here:https://github.com/rasbt/mlxtend/blob/master/mlxtend/evaluate/bias_variance_decomp.py )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# MODEL 1: using all predictor variables\n",
    "reg1 = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "# MODEL 2: using only AGE, NOX, DIS, and RAD as predictor variables\n",
    "ind2 = np.where([a in ['AGE','NOX','DIS','RAD'] for a in boston_bunch.feature_names])[0]\n",
    "reg2 = LinearRegression().fit(X_train[:,ind2], y_train)\n",
    "\n",
    "# MODEL 3: using all polynomial combinations of degree  â‰¤2  of the original thirteen predictor variables\n",
    "import sklearn.preprocessing as prepro\n",
    "poly = prepro.PolynomialFeatures(2)\n",
    "X_train_enhanced = poly.fit_transform(X_train)\n",
    "X_test_enhanced = poly.fit_transform(X_test)\n",
    "reg3 = LinearRegression().fit(X_train_enhanced, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1's MSE, Bias, Var: 30.329931, 29.074385, 1.255546 \n",
      "Model 2's MSE, Bias, Var: 76.069107, 75.267040, 0.802066 \n",
      "Model 3's MSE, Bias, Var: 375.233667, 20.588502, 354.645166 \n"
     ]
    }
   ],
   "source": [
    "#!pip install mlxtend\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "# Model 1\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(reg1, X_train, y_train, X_test, y_test,loss='mse',num_rounds= 100, random_seed=123)\n",
    "print(\"Model 1's MSE, Bias, Var: %f, %f, %f \" % (avg_expected_loss, avg_bias,avg_var))\n",
    "\n",
    "#Model 2\n",
    "avg_expected_loss2, avg_bias2, avg_var2 = bias_variance_decomp(reg2, X_train[:,ind2], y_train, X_test[:,ind2], y_test,loss='mse',num_rounds=100,random_seed=123)\n",
    "print(\"Model 2's MSE, Bias, Var: %f, %f, %f \" % (avg_expected_loss2, avg_bias2,avg_var2))\n",
    "\n",
    "#Model 3\n",
    "avg_expected_loss3, avg_bias3, avg_var3 = bias_variance_decomp(reg3, X_train_enhanced, y_train, X_test_enhanced, y_test,loss='mse',num_rounds= 100, random_seed=  123)\n",
    "print(\"Model 3's MSE, Bias, Var: %f, %f, %f \" % (avg_expected_loss3, avg_bias3, avg_var3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2\n",
    "In fact, as we add more and more parameters to our model, its complexity increases, which results in increasing variance and decreasing bias, i.e., overfitting. See the picture: <img src=\"https://cdn.analyticsvidhya.com/wp-content/uploads/2017/06/05153332/model-complex.png\" alt=\"image info\" /> So we need to balance the variance and the bias. In practice, we usually use regularization to overcome overfitting.\n",
    "\n",
    "Implement Ridge Regression and LASSO Regression on the enhanced dataset. Compute the $R^{2}$, variance, bias and MSE. Which one performs better?.(use alpha = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 4's training set R2, test set R2, MSE, Bias, Var: 0.942414,0.818889,30.761943, 16.741151, 14.020792 \n",
      "Model 5's training set R2, test set R2, MSE, Bias, Var: 0.922681,0.807759,22.543665, 17.879390, 4.664275 \n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge,Lasso\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import warnings\n",
    "\n",
    "reg4 = Ridge(alpha=0.1).fit(X_train_enhanced, y_train)\n",
    "R2_train = reg4.score(X_train_enhanced,y_train)\n",
    "R2_test = reg4.score(X_test_enhanced,y_test)\n",
    "avg_expected_loss4, avg_bias4, avg_var4 = bias_variance_decomp(reg4, X_train_enhanced, y_train, X_test_enhanced, y_test,loss='mse',num_rounds= 100, random_seed=  123)\n",
    "print(\"Model 4's training set R2, test set R2, MSE, Bias, Var: %f,%f,%f, %f, %f \" % (R2_train,R2_test,avg_expected_loss4, avg_bias4, avg_var4))\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning) # this is to suppress warnings related to the optimization in the training of Lasso\n",
    "reg5 = Lasso(alpha=0.1).fit(X_train_enhanced, y_train)\n",
    "R2_train_5 = reg5.score(X_train_enhanced,y_train)\n",
    "R2_test_5 = reg5.score(X_test_enhanced,y_test)\n",
    "avg_expected_loss5, avg_bias5, avg_var5 = bias_variance_decomp(reg5, X_train_enhanced, y_train, X_test_enhanced, y_test,loss='mse',num_rounds= 100, random_seed=  123)\n",
    "print(\"Model 5's training set R2, test set R2, MSE, Bias, Var: %f,%f,%f, %f, %f \" % (R2_train_5,R2_test_5,avg_expected_loss5, avg_bias5, avg_var5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3\n",
    "Now implement Ridge Regression and LASSO Regression on the original dataset. Change the values of the hyperparameters of Ridge and LASSO, how does the magnitude of the coefficients change? Is there any difference between these two methods? If we have a large dataset with 10,000 features, and some of the independent features are correlated with other independent features, which regression would you use, Ridge or LASSO?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.09694695e-01  4.87796793e-02  6.00389621e-02  2.33204686e+00\n",
      " -1.66912244e+01  4.06068613e+00  1.50662965e-02 -1.25022813e+00\n",
      "  3.71520546e-01 -1.52345646e-02 -9.44628972e-01  1.01469212e-02\n",
      " -5.41447857e-01]\n",
      "[-1.07243922e-01  4.96802447e-02  3.16703636e-02  2.20691944e+00\n",
      " -1.10650624e+01  4.09992200e+00  1.01624370e-02 -1.17629314e+00\n",
      "  3.60534305e-01 -1.58028537e-02 -8.84461645e-01  1.03427764e-02\n",
      " -5.47704300e-01]\n",
      "[-0.08286329  0.05152916 -0.          0.         -0.          2.6772327\n",
      "  0.01897004 -0.75779683  0.32597057 -0.01746293 -0.77193667  0.00921241\n",
      " -0.65953976]\n"
     ]
    }
   ],
   "source": [
    "reg6 = Ridge(alpha=0.5).fit(X_train, y_train)\n",
    "reg7 = Lasso(alpha=0.5).fit(X_train, y_train)\n",
    "print(reg1.coef_)\n",
    "print(reg6.coef_)\n",
    "print(reg7.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Principal Component Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1\n",
    "For the Boston house prices dataset, split the dataset into a training and test set using 2/5 as the test size and a random state of 553, and use polynomial features of degree 3, then run standard LinearRegression. Can you interpret the resulting test and training error in the context of the bias-variance tradeoff? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 8's MSE, Bias, Var:85952.579571, 1882.715186, 84069.864385 \n"
     ]
    }
   ],
   "source": [
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X, y, test_size=2/5, random_state=553)\n",
    "poly1 = prepro.PolynomialFeatures(3)\n",
    "X_train1_enhanced = poly1.fit_transform(X_train1)\n",
    "X_test1_enhanced = poly1.fit_transform(X_test1)\n",
    "reg8 = LinearRegression().fit(X_train1_enhanced, y_train1)\n",
    "avg_expected_loss6, avg_bias6, avg_var6 = bias_variance_decomp(reg8, X_train1_enhanced, y_train1, X_test1_enhanced, y_test1,loss='mse',num_rounds= 100, random_seed=  123)\n",
    "print(\"Model 8's MSE, Bias, Var:%f, %f, %f \" % (avg_expected_loss6, avg_bias6, avg_var6))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2\n",
    "Apply PCA with a number of 5, 50, 100 and 200 principal component, and run LinearRegression subsequently on the resulting principal components. What can be observed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "n_components=339 must be between 0 and min(n_samples, n_features)=13 with svd_solver='full'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-55-88832fd7e9ac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mpca\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecomposition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPCA\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# sklearn uses a different convention\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mpca\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# note the transpose\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;31m# pca.transform(X.T)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpca\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomponents_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpca\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexplained_variance_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_pca.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    350\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mitself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m         \"\"\"\n\u001b[1;32m--> 352\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    353\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_pca.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    421\u001b[0m         \u001b[1;31m# Call different fits for either full or truncated SVD\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_svd_solver\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'full'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 423\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_full\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    424\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_svd_solver\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'arpack'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'randomized'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    425\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_truncated\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_svd_solver\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_pca.py\u001b[0m in \u001b[0;36m_fit_full\u001b[1;34m(self, X, n_components)\u001b[0m\n\u001b[0;32m    437\u001b[0m                                  \"if n_samples >= n_features\")\n\u001b[0;32m    438\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mn_components\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 439\u001b[1;33m             raise ValueError(\"n_components=%r must be between 0 and \"\n\u001b[0m\u001b[0;32m    440\u001b[0m                              \u001b[1;34m\"min(n_samples, n_features)=%r with \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m                              \u001b[1;34m\"svd_solver='full'\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: n_components=339 must be between 0 and min(n_samples, n_features)=13 with svd_solver='full'"
     ]
    }
   ],
   "source": [
    "from sklearn import decomposition\n",
    "pca = decomposition.PCA(n_components=X_train[:,12].size)\n",
    "# sklearn uses a different convention\n",
    "pca.fit(X_train.T) # note the transpose\n",
    "# pca.transform(X.T)\n",
    "print (pca.components_.T, pca.explained_variance_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
